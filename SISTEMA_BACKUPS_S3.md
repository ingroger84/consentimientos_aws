# ðŸ’¾ Sistema de Backups Automatizados a S3

## ðŸŽ¯ Arquitectura de Backups

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SISTEMA DE BACKUPS                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  PostgreSQL  â”€â”€â–º  pg_dump  â”€â”€â–º  gzip  â”€â”€â–º  AWS S3          â”‚
â”‚                                                              â”‚
â”‚  Frecuencia: Diaria (3:00 AM)                              â”‚
â”‚  RetenciÃ³n: 30 dÃ­as                                         â”‚
â”‚  Bucket: datagree-backups                                   â”‚
â”‚  Storage Class: STANDARD_IA (bajo costo)                   â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“¦ PASO 1: Crear Bucket S3 para Backups

### OpciÃ³n A: Desde AWS Console

1. Ir a S3 Console: https://s3.console.aws.amazon.com/
2. Click "Create bucket"
3. ConfiguraciÃ³n:
   ```
   Bucket name: datagree-backups
   Region: us-east-1 (mismo que datagree-uploads)
   Block all public access: âœ… ENABLED
   Bucket Versioning: âœ… ENABLED (recomendado)
   Default encryption: âœ… SSE-S3
   ```
4. Click "Create bucket"

### OpciÃ³n B: Desde AWS CLI

```bash
# Crear bucket
aws s3 mb s3://datagree-backups --region us-east-1

# Habilitar versionamiento
aws s3api put-bucket-versioning \
  --bucket datagree-backups \
  --versioning-configuration Status=Enabled

# Habilitar encriptaciÃ³n
aws s3api put-bucket-encryption \
  --bucket datagree-backups \
  --server-side-encryption-configuration '{
    "Rules": [{
      "ApplyServerSideEncryptionByDefault": {
        "SSEAlgorithm": "AES256"
      }
    }]
  }'

# Bloquear acceso pÃºblico
aws s3api put-public-access-block \
  --bucket datagree-backups \
  --public-access-block-configuration \
    "BlockPublicAcls=true,IgnorePublicAcls=true,BlockPublicPolicy=true,RestrictPublicBuckets=true"
```

---

## ðŸ“¦ PASO 2: Configurar Lifecycle Policy (Ahorro de Costos)

```bash
# Crear archivo de polÃ­tica
cat > lifecycle-policy.json << 'EOF'
{
  "Rules": [
    {
      "Id": "TransitionToIA",
      "Status": "Enabled",
      "Transitions": [
        {
          "Days": 7,
          "StorageClass": "STANDARD_IA"
        },
        {
          "Days": 30,
          "StorageClass": "GLACIER"
        }
      ],
      "Expiration": {
        "Days": 90
      }
    }
  ]
}
EOF

# Aplicar polÃ­tica
aws s3api put-bucket-lifecycle-configuration \
  --bucket datagree-backups \
  --lifecycle-configuration file://lifecycle-policy.json
```

**Ahorro estimado:**
- STANDARD: $0.023/GB/mes
- STANDARD_IA: $0.0125/GB/mes (45% mÃ¡s barato)
- GLACIER: $0.004/GB/mes (83% mÃ¡s barato)


---

## ðŸ“¦ PASO 3: Configurar Permisos IAM

### Crear polÃ­tica IAM para backups:

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "BackupToS3",
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:DeleteObject"
      ],
      "Resource": [
        "arn:aws:s3:::datagree-backups",
        "arn:aws:s3:::datagree-backups/*"
      ]
    }
  ]
}
```

**Nota:** Las credenciales AWS actuales ya tienen permisos S3 completos.

---

## ðŸ“¦ PASO 4: Instalar Scripts de Backup en el Servidor

```bash
# Conectar al servidor
ssh -i "AWS-ISSABEL.pem" ubuntu@100.28.198.249

# Crear directorio para scripts
sudo mkdir -p /opt/datagree/scripts
cd /opt/datagree/scripts

# Los scripts ya estÃ¡n creados localmente, subirlos:
```

Desde tu mÃ¡quina local:

```powershell
# Subir scripts
scp -i "AWS-ISSABEL.pem" backend/scripts/backup-to-s3.sh ubuntu@100.28.198.249:/tmp/
scp -i "AWS-ISSABEL.pem" backend/scripts/restore-from-s3.sh ubuntu@100.28.198.249:/tmp/

# En el servidor, mover y dar permisos
ssh -i "AWS-ISSABEL.pem" ubuntu@100.28.198.249
sudo mv /tmp/backup-to-s3.sh /opt/datagree/scripts/
sudo mv /tmp/restore-from-s3.sh /opt/datagree/scripts/
sudo chmod +x /opt/datagree/scripts/*.sh
```

---

## ðŸ“¦ PASO 5: Configurar Variables de Entorno

```bash
# Editar .bashrc o crear archivo de configuraciÃ³n
sudo nano /opt/datagree/scripts/backup.env
```

Contenido:

```bash
# ConfiguraciÃ³n de Base de Datos
export DB_DATABASE=consentimientos
export DB_USERNAME=datagree_admin
export DB_PASSWORD=DataGree2026!Secure

# ConfiguraciÃ³n de S3
export BACKUP_S3_BUCKET=datagree-backups
export AWS_DEFAULT_REGION=us-east-1

# Las credenciales AWS ya estÃ¡n configuradas en el sistema
```

```bash
# Dar permisos seguros
sudo chmod 600 /opt/datagree/scripts/backup.env
```

---

## ðŸ“¦ PASO 6: Configurar Cron para Backups AutomÃ¡ticos

```bash
# Editar crontab
crontab -e
```

Agregar estas lÃ­neas:

```cron
# Backup diario a las 3:00 AM (hora del servidor)
0 3 * * * source /opt/datagree/scripts/backup.env && /opt/datagree/scripts/backup-to-s3.sh >> /var/log/datagree-backup.log 2>&1

# Backup semanal completo los domingos a las 2:00 AM
0 2 * * 0 source /opt/datagree/scripts/backup.env && /opt/datagree/scripts/backup-to-s3.sh >> /var/log/datagree-backup-weekly.log 2>&1
```

**Frecuencias recomendadas:**
- Diario: Datos crÃ­ticos (base de datos)
- Semanal: Backup completo + archivos
- Mensual: Backup archivado a Glacier


---

## ðŸ“¦ PASO 7: Probar el Sistema de Backups

### Prueba Manual:

```bash
# Cargar variables de entorno
source /opt/datagree/scripts/backup.env

# Ejecutar backup manual
/opt/datagree/scripts/backup-to-s3.sh
```

**Salida esperada:**
```
ðŸ”„ Iniciando backup de base de datos...
ðŸ“¦ Creando dump de PostgreSQL...
âœ… Backup creado: /tmp/backups/consentimientos_20260209_150000.sql.gz (15M)
â˜ï¸  Subiendo a S3...
âœ… Backup subido exitosamente a S3
   ðŸ“ s3://datagree-backups/database-backups/consentimientos_20260209_150000.sql.gz
ðŸ§¹ Archivo local eliminado
ðŸ—‘ï¸  Limpiando backups antiguos (>30 dÃ­as)...
âœ… Backup completado exitosamente
```

### Verificar en S3:

```bash
# Listar backups
aws s3 ls s3://datagree-backups/database-backups/

# Ver detalles de un backup
aws s3api head-object \
  --bucket datagree-backups \
  --key database-backups/consentimientos_20260209_150000.sql.gz
```

---

## ðŸ“¦ PASO 8: Probar RestauraciÃ³n

âš ï¸ **ADVERTENCIA:** Solo probar en ambiente de desarrollo o staging

```bash
# Listar backups disponibles
aws s3 ls s3://datagree-backups/database-backups/

# Restaurar un backup especÃ­fico
/opt/datagree/scripts/restore-from-s3.sh consentimientos_20260209_150000.sql.gz
```

---

## ðŸ“Š MONITOREO Y ALERTAS

### Crear Script de VerificaciÃ³n:

```bash
# /opt/datagree/scripts/check-backups.sh
#!/bin/bash

BUCKET="datagree-backups"
PREFIX="database-backups"
MAX_AGE_HOURS=26 # Alertar si no hay backup en 26 horas

# Obtener Ãºltimo backup
LAST_BACKUP=$(aws s3 ls s3://$BUCKET/$PREFIX/ | sort | tail -1 | awk '{print $4}')

if [ -z "$LAST_BACKUP" ]; then
    echo "âŒ ERROR: No se encontraron backups"
    exit 1
fi

# Extraer timestamp del nombre del archivo
BACKUP_DATE=$(echo $LAST_BACKUP | grep -oP '\d{8}_\d{6}')
BACKUP_TIMESTAMP=$(date -d "${BACKUP_DATE:0:8} ${BACKUP_DATE:9:2}:${BACKUP_DATE:11:2}:${BACKUP_DATE:13:2}" +%s)
CURRENT_TIMESTAMP=$(date +%s)
AGE_HOURS=$(( ($CURRENT_TIMESTAMP - $BACKUP_TIMESTAMP) / 3600 ))

if [ $AGE_HOURS -gt $MAX_AGE_HOURS ]; then
    echo "âš ï¸  ALERTA: Ãšltimo backup tiene $AGE_HOURS horas"
    echo "   Archivo: $LAST_BACKUP"
    exit 1
else
    echo "âœ… Backup reciente encontrado ($AGE_HOURS horas)"
    echo "   Archivo: $LAST_BACKUP"
    exit 0
fi
```

```bash
# Dar permisos
sudo chmod +x /opt/datagree/scripts/check-backups.sh

# Agregar a cron (verificar cada 6 horas)
0 */6 * * * /opt/datagree/scripts/check-backups.sh || echo "ALERTA: Problema con backups" | mail -s "Backup Alert" admin@tudominio.com
```

---

## ðŸ’° ESTIMACIÃ“N DE COSTOS

### Escenario: Base de datos de 500MB

**Almacenamiento:**
```
Backup diario: 500MB x 30 dÃ­as = 15GB
Backup semanal: 500MB x 4 = 2GB
Total: ~17GB

Costos mensuales:
- Primeros 7 dÃ­as (STANDARD): 3.5GB x $0.023 = $0.08
- DÃ­as 8-30 (STANDARD_IA): 13.5GB x $0.0125 = $0.17
- Total: ~$0.25/mes
```

**Transferencia:**
- Upload a S3: GRATIS
- Download (restauraciÃ³n): $0.09/GB (solo cuando se use)

**Total estimado: $0.25 - $0.50/mes** ðŸ’°

---

## ðŸ” SEGURIDAD Y MEJORES PRÃCTICAS

### 1. EncriptaciÃ³n
âœ… Backups encriptados en reposo (SSE-S3)
âœ… Transferencia encriptada (HTTPS)

### 2. Control de Acceso
âœ… Bucket privado (no acceso pÃºblico)
âœ… IAM policies restrictivas
âœ… Versionamiento habilitado

### 3. RetenciÃ³n
âœ… 30 dÃ­as en STANDARD_IA
âœ… 90 dÃ­as en GLACIER
âœ… EliminaciÃ³n automÃ¡tica despuÃ©s de 90 dÃ­as

### 4. VerificaciÃ³n
âœ… Logs de cada backup
âœ… Monitoreo automÃ¡tico
âœ… Alertas por email

### 5. Disaster Recovery
âœ… Backups en regiÃ³n diferente (opcional)
âœ… Scripts de restauraciÃ³n probados
âœ… DocumentaciÃ³n completa

---

## ðŸ“‹ CHECKLIST DE IMPLEMENTACIÃ“N

- [ ] Crear bucket S3 `datagree-backups`
- [ ] Configurar lifecycle policy
- [ ] Subir scripts al servidor
- [ ] Configurar variables de entorno
- [ ] Configurar cron jobs
- [ ] Probar backup manual
- [ ] Probar restauraciÃ³n (en dev)
- [ ] Configurar monitoreo
- [ ] Documentar procedimientos
- [ ] Entrenar al equipo

---

## ðŸ†˜ TROUBLESHOOTING

### Error: "Permission denied"
```bash
# Verificar permisos del script
ls -l /opt/datagree/scripts/backup-to-s3.sh
sudo chmod +x /opt/datagree/scripts/backup-to-s3.sh
```

### Error: "AWS credentials not found"
```bash
# Verificar credenciales
aws sts get-caller-identity

# Si falla, configurar:
aws configure
```

### Error: "pg_dump: command not found"
```bash
# Instalar PostgreSQL client
sudo apt-get install postgresql-client
```

### Backup muy lento
```bash
# Usar compresiÃ³n paralela
pg_dump ... | pigz > backup.sql.gz
```

---

## ðŸ“š RECURSOS ADICIONALES

- [AWS S3 Pricing](https://aws.amazon.com/s3/pricing/)
- [PostgreSQL Backup Best Practices](https://www.postgresql.org/docs/current/backup.html)
- [AWS CLI S3 Commands](https://docs.aws.amazon.com/cli/latest/reference/s3/)

---

**Implementado por:** Kiro AI  
**Fecha:** 2026-02-09  
**VersiÃ³n:** 1.0
